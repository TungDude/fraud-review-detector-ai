{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Synthetic Fake Review Gen (Ollama + Gemma 3)\n",
    "\n",
    "This notebook generates synthetic fake reviews using different sizes of Gemma 3 models running via Ollama.\n",
    "\n",
    "## Models & Roles\n",
    "\n",
    "1.  **Small Models (`gemma3:1b`)**\n",
    "    *   **Role:** \"Spam Bot\" Simulator\n",
    "    *   **Characteristics:** Low coherence, repetitive, rigid patterns, grammatical looseness.\n",
    "    *   **Goal:** Simulate mass-generated low-effort spam.\n",
    "\n",
    "2.  **Medium/Large Models (`gemma3:4b`, `gemma3:12b`)**\n",
    "    *   **Role:** \"Paid Reviewer\" Simulator\n",
    "    *   **Characteristics:** High reasoning, nuanced, can follow complex instructions (e.g., \"mixed\" sentiment).\n",
    "    *   **Goal:** Simulate sophisticated attacks, competitor sabotage, or paid boosting.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1.  Ensure [Ollama](https://ollama.com/) is installed and running.\n",
    "2.  Pull the required models:\n",
    "    ```bash\n",
    "    ollama pull gemma3:1b\n",
    "    ollama pull gemma3:4b\n",
    "    ollama pull gemma3:12b\n",
    "    ```\n",
    "    *(Note: Adjust model tags if exact names differ in your registry)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas ollama tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"small\": [\"gemma3:1b\"],\n",
    "    \"medium\": [\"gemma3:4b\"],\n",
    "    \"large\": [\"gemma3:12b\"]\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = \"../dataset/synthetic\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "PRODUCTS = [\n",
    "    \"Wireless Noise Cancelling Headphones\",\n",
    "    \"Organic Vitamin C Serum\",\n",
    "    \"Smart Home Security Camera\",\n",
    "    \"Ergonomic Office Chair\",\n",
    "    \"Gaming Laptop 15-inch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAM_BOT_PROMPTS = [\n",
    "    \"Write a very short, generic positive review for {product}. Use poor grammar and repetitive words like 'good' or 'nice'.\",\n",
    "    \"Generate a spammy looking review for {product}. It should look like a bot wrote it. Keep it under 10 words.\",\n",
    "    \"Write a review for {product} that says 'Great project' or 'Nice sir' even though it is a product.\",\n",
    "    \"Write a 5-star review for {product} using only broken English and emojis.\"\n",
    "]\n",
    "PAID_REVIEWER_PROMPTS = [\n",
    "    \"Write a detailed positive review for {product}. Mention specific features like battery life or build quality. Make it sound enthusiastic but slightly overly salesy.\",\n",
    "    \"Write a negative review for {product} claiming the delivery was rude, but admit the product itself is okay. This is to damage the seller's reputation subtly.\",\n",
    "    \"Write a mixed review for {product}. Praise the design but complain about a specific made-up defect to make it sound authentic.\",\n",
    "    \"You are a paid reviewer. Write a convincing 5-star review for {product} that addresses common complaints found in other reviews to neutralize them.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generation-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reviews(model_name, role_type, prompts, count_per_prompt=5):\n",
    "    generated_data = []\n",
    "    \n",
    "    print(f\"Generating with {model_name} ({role_type})\")\n",
    "    \n",
    "    for product in PRODUCTS:\n",
    "        for prompt_template in prompts:\n",
    "            prompt = prompt_template.format(product=product)\n",
    "            \n",
    "            for _ in tqdm(range(count_per_prompt), desc=f\"{product[:15]}...\", leave=False):\n",
    "                try:\n",
    "                    response = ollama.generate(model=model_name, prompt=prompt)\n",
    "                    review_text = response['response'].strip()\n",
    "                    \n",
    "                    generated_data.append({\n",
    "                        \"model\": model_name,\n",
    "                        \"role_type\": role_type,\n",
    "                        \"product\": product,\n",
    "                        \"prompt_used\": prompt,\n",
    "                        \"review_text\": review_text,\n",
    "                        \"label\": \"fake\"\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating with {model_name}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "    return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "run-small",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with gemma3:1b (spam_bot)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "small_model_data = []\n",
    "\n",
    "for model in MODELS[\"small\"]:\n",
    "    try:\n",
    "        data = generate_reviews(\n",
    "            model_name=model,\n",
    "            role_type=\"spam_bot\",\n",
    "            prompts=SPAM_BOT_PROMPTS,\n",
    "            count_per_prompt=5\n",
    "        )\n",
    "        small_model_data.extend(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {model}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-medium-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with gemma3:4b (paid_reviewer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wireless Noise ...:  20%|██        | 1/5 [00:26<01:46, 26.72s/it]"
     ]
    }
   ],
   "source": [
    "complex_model_data = []\n",
    "\n",
    "target_models = MODELS[\"medium\"] + MODELS[\"large\"]\n",
    "\n",
    "for model in target_models:\n",
    "    try:\n",
    "        data = generate_reviews(\n",
    "            model_name=model,\n",
    "            role_type=\"paid_reviewer\",\n",
    "            prompts=PAID_REVIEWER_PROMPTS,\n",
    "            count_per_prompt=5\n",
    "        )\n",
    "        complex_model_data.extend(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {model}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = small_model_data + complex_model_data\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "if not df.empty:\n",
    "    csv_path = f\"{OUTPUT_DIR}/generated_fake_reviews_gemma3.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {len(df)} generated reviews to {csv_path}\")\n",
    "    \n",
    "    print(\"\\nSample Spam Bot Reviews:\")\n",
    "    print(df[df['role_type'] == 'spam_bot'][['model', 'review_text']].head(3))\n",
    "    \n",
    "    print(\"\\nSample Paid Reviewer Reviews:\")\n",
    "    print(df[df['role_type'] == 'paid_reviewer'][['model', 'review_text']].head(3))\n",
    "else:\n",
    "    print(\"No data generated. Check if Ollama is running and models are available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(df.groupby(['model', 'role_type']).size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
